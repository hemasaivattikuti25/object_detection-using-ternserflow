{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8df901a4-989f-4121-9a54-a2bb848f0d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8df901a4-989f-4121-9a54-a2bb848f0d6f",
        "outputId": "43030bf5-be61-47e9-ad27-0e8256196e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tf-models-official 2.19.1 requires tensorflow~=2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mfatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.66.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (11.2.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (3.0.12)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.0.10)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (1.15.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.19.1)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.11/dist-packages (from object_detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.173.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: ai-edge-litert>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.3.0)\n",
            "Collecting tensorflow~=2.19.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tensorflow-text~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (3.10.18)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (1.11.1)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (1.65.5)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.24.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (24.2)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.25.8)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (4.14.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.23.0)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->object_detection==0.1) (0.7)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->object_detection==0.1) (0.3.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from lvis->object_detection==0.1) (1.4.8)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.11/dist-packages (from lvis->object_detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->object_detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->object_detection==0.1) (4.58.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: backports.strenum in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (1.2.8)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (25.2.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.25.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: PyJWT~=2.9.0 in /usr/local/lib/python3.11/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.17.2)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ml-dtypes (from keras->object_detection==0.1)\n",
            "  Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.12.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.5.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.2)\n",
            "Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "Building wheels for collected packages: object_detection\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697325 sha256=ffe776207ef1c8de6e257a3f9c63704e82e55b7c317d4b8290434ab44e29dde7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fg3bxf5a/wheels/95/4a/63/b2d36ca06eab841de19a38993ffaf2beac152a44539bc642a6\n",
            "Successfully built object_detection\n",
            "Installing collected packages: ml-dtypes, tensorboard, tensorflow, object_detection\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.2\n",
            "    Uninstalling ml-dtypes-0.3.2:\n",
            "      Successfully uninstalled ml-dtypes-0.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.16.2\n",
            "    Uninstalling tensorboard-2.16.2:\n",
            "      Successfully uninstalled tensorboard-2.16.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.16.1\n",
            "    Uninstalling tensorflow-2.16.1:\n",
            "      Successfully uninstalled tensorflow-2.16.1\n",
            "  Attempting uninstall: object_detection\n",
            "    Found existing installation: object_detection 0.1\n",
            "    Uninstalling object_detection-0.1:\n",
            "      Successfully uninstalled object_detection-0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.5.1 object_detection-0.1 tensorboard-2.19.0 tensorflow-2.19.0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.16.1 opencv-python-headless pillow lxml matplotlib --quiet\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!pip install .\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "708b9da7-b5b2-4653-8111-1057d5f3da71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "708b9da7-b5b2-4653-8111-1057d5f3da71",
        "outputId": "173dd898-ca0f-4101-e088-87c71f57605e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e0348ef3-c4bb-4dbb-98ca-b01a613bcefd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e0348ef3-c4bb-4dbb-98ca-b01a613bcefd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving archive.zip to archive.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "42040817-c3dd-423b-8aa2-7343a1e3316e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42040817-c3dd-423b-8aa2-7343a1e3316e",
        "outputId": "85aaa4f2-e880-4e84-ef9e-651c8d0057a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset extracted to: dataset\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"archive.zip\"  # same name you uploaded\n",
        "extract_dir = \"dataset\"\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"✅ Dataset extracted to:\", extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b9e55de6-22d6-400d-8f50-20c6eb8c5ee2",
      "metadata": {
        "id": "b9e55de6-22d6-400d-8f50-20c6eb8c5ee2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5dfdbe9f-6833-43c6-af12-6ce1360d0d78",
      "metadata": {
        "id": "5dfdbe9f-6833-43c6-af12-6ce1360d0d78"
      },
      "outputs": [],
      "source": [
        "base_dir = 'dataset/archive'  # because zip extracted into this path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6ef46243-6670-4a69-b5f6-a166c31e1452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ef46243-6670-4a69-b5f6-a166c31e1452",
        "outputId": "c06640c3-1047-4982-ac33-2abf4abd179c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3561 images belonging to 5 classes.\n",
            "Found 888 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "be0e6faf-c792-41ea-a279-d479902e89f9",
      "metadata": {
        "id": "be0e6faf-c792-41ea-a279-d479902e89f9"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c5afe55f-c80c-4788-a4f0-b600a1511681",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5afe55f-c80c-4788-a4f0-b600a1511681",
        "outputId": "7ad42843-cc91-459e-a330-0a4125b68d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3561 images belonging to 5 classes.\n",
            "Found 888 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set base directory — update this if your folder name is different\n",
        "base_dir = 'dataset/archive'  # this is where Butterfly, Mosquito etc. folders are\n",
        "\n",
        "# Create ImageDataGenerator for training and validation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "# Training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "09ee50ff-956a-493b-aa16-8e56f0719731",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ee50ff-956a-493b-aa16-8e56f0719731",
        "outputId": "2b004b0b-e7a7-46a3-8c4a-2ac3f62159fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2881 - loss: 2.4831"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 2s/step - accuracy: 0.2887 - loss: 2.4760 - val_accuracy: 0.3637 - val_loss: 1.4864\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=1  # You can increase for better accuracy\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "UWNAi8riM9hZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWNAi8riM9hZ",
        "outputId": "56ef422e-b3aa-4a8c-c00c-68e457ff2fad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the model even if partially trained\n",
        "model.save(\"quick_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f00490-1b7d-49ef-8e59-67ada95b033d",
      "metadata": {
        "id": "c7f00490-1b7d-49ef-8e59-67ada95b033d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9f0f93f8-c364-4fb9-bb02-3a42a3978411",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0f93f8-c364-4fb9-bb02-3a42a3978411",
        "outputId": "186f6c0a-1e7b-43f6-fed2-d78c4e5f165e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 529ms/step - accuracy: 0.4013 - loss: 1.4485\n",
            "Validation Accuracy: 38.51%\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "print(f\"Validation Accuracy: {val_acc*2:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6987ff4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6987ff4d",
        "outputId": "b7a7d193-3b96-4cdc-ee40-7e7c7a5e887c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "google0.jpg    google341.jpg  google573.jpg\t  istockphoto308.jpg\n",
            "google100.jpg  google342.jpg  google574.jpg\t  istockphoto30.jpg\n",
            "google101.jpg  google343.jpg  google575.jpg\t  istockphoto310.jpg\n",
            "google102.jpg  google344.jpg  google576.jpg\t  istockphoto311.jpg\n",
            "google103.jpg  google345.jpg  google578.jpg\t  istockphoto312.jpg\n",
            "google104.jpg  google346.jpg  google579.jpg\t  istockphoto313.jpg\n",
            "google105.jpg  google347.jpg  google57.jpg\t  istockphoto314.jpg\n",
            "google107.jpg  google349.jpg  google580.jpg\t  istockphoto315.jpg\n",
            "google109.jpg  google34.jpg   google581.jpg\t  istockphoto316.jpg\n",
            "google10.jpg   google350.jpg  google582.jpg\t  istockphoto318.jpg\n",
            "google110.jpg  google351.jpg  google583.jpg\t  istockphoto31.jpg\n",
            "google111.jpg  google352.jpg  google584.jpg\t  istockphoto32.jpg\n",
            "google112.jpg  google353.jpg  google586.jpg\t  istockphoto342.jpg\n",
            "google113.jpg  google354.jpg  google587.jpg\t  istockphoto343.jpg\n",
            "google114.jpg  google355.jpg  google588.jpg\t  istockphoto344.jpg\n",
            "google118.jpg  google356.jpg  google590.jpg\t  istockphoto345.jpg\n",
            "google119.jpg  google357.jpg  google591.jpg\t  istockphoto346.jpg\n",
            "google11.jpg   google359.jpg  google592.jpg\t  istockphoto348.jpg\n",
            "google120.jpg  google35.jpg   google593.jpg\t  istockphoto349.jpg\n",
            "google121.jpg  google360.jpg  google594.jpg\t  istockphoto350.jpg\n",
            "google122.jpg  google361.jpg  google595.jpg\t  istockphoto351.jpg\n",
            "google123.jpg  google362.jpg  google596.jpg\t  istockphoto352.jpg\n",
            "google124.jpg  google363.jpg  google597.jpg\t  istockphoto353.jpg\n",
            "google125.jpg  google364.jpg  google598.jpg\t  istockphoto354.jpg\n",
            "google126.jpg  google365.jpg  google59.jpg\t  istockphoto355.jpg\n",
            "google127.jpg  google366.jpg  google5.jpg\t  istockphoto356.jpg\n",
            "google128.jpg  google367.jpg  google60.jpg\t  istockphoto358.jpg\n",
            "google129.jpg  google368.jpg  google61.jpg\t  istockphoto359.jpg\n",
            "google12.jpg   google369.jpg  google62.jpg\t  istockphoto35.jpg\n",
            "google130.jpg  google36.jpg   google63.jpg\t  istockphoto361.jpg\n",
            "google131.jpg  google370.jpg  google64.jpg\t  istockphoto363.jpg\n",
            "google132.jpg  google371.jpg  google65.jpg\t  istockphoto365.jpg\n",
            "google133.jpg  google372.jpg  google66.jpg\t  istockphoto366.jpg\n",
            "google134.jpg  google373.jpg  google67.jpg\t  istockphoto367.jpg\n",
            "google135.jpg  google374.jpg  google68.jpg\t  istockphoto368.jpg\n",
            "google136.jpg  google375.jpg  google69.jpg\t  istockphoto369.jpg\n",
            "google137.jpg  google376.jpg  google6.jpg\t  istockphoto36.jpg\n",
            "google138.jpg  google377.jpg  google70.jpg\t  istockphoto370.jpg\n",
            "google139.jpg  google379.jpg  google71.jpg\t  istockphoto371.jpg\n",
            "google13.jpg   google37.jpg   google72.jpg\t  istockphoto372.jpg\n",
            "google141.jpg  google380.jpg  google73.jpg\t  istockphoto373.jpg\n",
            "google143.jpg  google381.jpg  google74.jpg\t  istockphoto374.jpg\n",
            "google144.jpg  google382.jpg  google76.jpg\t  istockphoto375.jpg\n",
            "google145.jpg  google383.jpg  google77.jpg\t  istockphoto376.jpg\n",
            "google146.jpg  google384.jpg  google78.jpg\t  istockphoto377.jpg\n",
            "google148.jpg  google385.jpg  google79.jpg\t  istockphoto378.jpg\n",
            "google149.jpg  google386.jpg  google7.jpg\t  istockphoto379.jpg\n",
            "google14.jpg   google387.jpg  google80.jpg\t  istockphoto37.jpg\n",
            "google150.jpg  google388.jpg  google81.jpg\t  istockphoto381.jpg\n",
            "google151.jpg  google389.jpg  google82.jpg\t  istockphoto382.jpg\n",
            "google152.jpg  google38.jpg   google83.jpg\t  istockphoto383.jpg\n",
            "google153.jpg  google390.jpg  google84.jpg\t  istockphoto384.jpg\n",
            "google154.jpg  google391.jpg  google85.jpg\t  istockphoto385.jpg\n",
            "google156.jpg  google392.jpg  google86.jpg\t  istockphoto386.jpg\n",
            "google157.jpg  google393.jpg  google87.jpg\t  istockphoto387.jpg\n",
            "google158.jpg  google394.jpg  google88.jpg\t  istockphoto388.jpg\n",
            "google159.jpg  google395.jpg  google89.jpg\t  istockphoto389.jpg\n",
            "google15.jpg   google396.jpg  google8.jpg\t  istockphoto38.jpg\n",
            "google163.jpg  google397.jpg  google90.jpg\t  istockphoto390.jpg\n",
            "google164.jpg  google398.jpg  google91.jpg\t  istockphoto391.jpg\n",
            "google165.jpg  google399.jpg  google92.jpg\t  istockphoto393.jpg\n",
            "google166.jpg  google39.jpg   google93.jpg\t  istockphoto394.jpg\n",
            "google168.jpg  google3.jpg    google94.jpg\t  istockphoto395.jpg\n",
            "google169.jpg  google400.jpg  google95.jpg\t  istockphoto396.jpg\n",
            "google16.jpg   google401.jpg  google96.jpg\t  istockphoto397.jpg\n",
            "google170.jpg  google402.jpg  google97.jpg\t  istockphoto398.jpg\n",
            "google171.jpg  google403.jpg  google98.jpg\t  istockphoto399.jpg\n",
            "google172.jpg  google404.jpg  google99.jpg\t  istockphoto39.jpg\n",
            "google173.jpg  google406.jpg  google9.jpg\t  istockphoto400.jpg\n",
            "google174.jpg  google407.jpg  istockphoto100.jpg  istockphoto41.jpg\n",
            "google175.jpg  google408.jpg  istockphoto101.jpg  istockphoto421.jpg\n",
            "google176.jpg  google409.jpg  istockphoto102.jpg  istockphoto422.jpg\n",
            "google177.jpg  google40.jpg   istockphoto103.jpg  istockphoto424.jpg\n",
            "google178.jpg  google410.jpg  istockphoto104.jpg  istockphoto425.jpg\n",
            "google179.jpg  google411.jpg  istockphoto105.jpg  istockphoto426.jpg\n",
            "google17.jpg   google412.jpg  istockphoto106.jpg  istockphoto427.jpg\n",
            "google180.jpg  google413.jpg  istockphoto107.jpg  istockphoto428.jpg\n",
            "google181.jpg  google414.jpg  istockphoto108.jpg  istockphoto429.jpg\n",
            "google182.jpg  google416.jpg  istockphoto109.jpg  istockphoto42.jpg\n",
            "google183.jpg  google419.jpg  istockphoto110.jpg  istockphoto430.jpg\n",
            "google184.jpg  google41.jpg   istockphoto111.jpg  istockphoto432.jpg\n",
            "google185.jpg  google420.jpg  istockphoto112.jpg  istockphoto433.jpg\n",
            "google186.jpg  google421.jpg  istockphoto113.jpg  istockphoto435.jpg\n",
            "google187.jpg  google422.jpg  istockphoto114.jpg  istockphoto436.jpg\n",
            "google188.jpg  google423.jpg  istockphoto115.jpg  istockphoto438.jpg\n",
            "google189.jpg  google424.jpg  istockphoto116.jpg  istockphoto439.jpg\n",
            "google18.jpg   google426.jpg  istockphoto117.jpg  istockphoto43.jpg\n",
            "google190.jpg  google427.jpg  istockphoto118.jpg  istockphoto441.jpg\n",
            "google191.jpg  google428.jpg  istockphoto119.jpg  istockphoto442.jpg\n",
            "google192.jpg  google429.jpg  istockphoto120.jpg  istockphoto443.jpg\n",
            "google193.jpg  google42.jpg   istockphoto121.jpg  istockphoto444.jpg\n",
            "google194.jpg  google432.jpg  istockphoto122.jpg  istockphoto445.jpg\n",
            "google195.jpg  google433.jpg  istockphoto123.jpg  istockphoto446.jpg\n",
            "google196.jpg  google434.jpg  istockphoto124.jpg  istockphoto447.jpg\n",
            "google197.jpg  google435.jpg  istockphoto125.jpg  istockphoto44.jpg\n",
            "google198.jpg  google436.jpg  istockphoto126.jpg  istockphoto450.jpg\n",
            "google199.jpg  google438.jpg  istockphoto127.jpg  istockphoto451.jpg\n",
            "google19.jpg   google439.jpg  istockphoto128.jpg  istockphoto452.jpg\n",
            "google1.jpg    google43.jpg   istockphoto129.jpg  istockphoto453.jpg\n",
            "google200.jpg  google440.jpg  istockphoto130.jpg  istockphoto456.jpg\n",
            "google201.jpg  google441.jpg  istockphoto131.jpg  istockphoto457.jpg\n",
            "google202.jpg  google442.jpg  istockphoto132.jpg  istockphoto458.jpg\n",
            "google203.jpg  google443.jpg  istockphoto134.jpg  istockphoto45.jpg\n",
            "google205.jpg  google446.jpg  istockphoto135.jpg  istockphoto460.jpg\n",
            "google206.jpg  google448.jpg  istockphoto136.jpg  istockphoto461.jpg\n",
            "google207.jpg  google449.jpg  istockphoto137.jpg  istockphoto463.jpg\n",
            "google20.jpg   google44.jpg   istockphoto138.jpg  istockphoto465.jpg\n",
            "google210.jpg  google452.jpg  istockphoto139.jpg  istockphoto467.jpg\n",
            "google213.jpg  google453.jpg  istockphoto140.jpg  istockphoto46.jpg\n",
            "google214.jpg  google454.jpg  istockphoto141.jpg  istockphoto471.jpg\n",
            "google215.jpg  google457.jpg  istockphoto142.jpg  istockphoto472.jpg\n",
            "google216.jpg  google458.jpg  istockphoto144.jpg  istockphoto474.jpg\n",
            "google217.jpg  google459.jpg  istockphoto145.jpg  istockphoto475.jpg\n",
            "google21.jpg   google45.jpg   istockphoto146.jpg  istockphoto478.jpg\n",
            "google220.jpg  google460.jpg  istockphoto147.jpg  istockphoto47.jpg\n",
            "google221.jpg  google461.jpg  istockphoto148.jpg  istockphoto480.jpg\n",
            "google222.jpg  google462.jpg  istockphoto150.jpg  istockphoto49.jpg\n",
            "google223.jpg  google463.jpg  istockphoto151.jpg  istockphoto502.jpg\n",
            "google224.jpg  google465.jpg  istockphoto152.jpg  istockphoto503.jpg\n",
            "google226.jpg  google466.jpg  istockphoto153.jpg  istockphoto504.jpg\n",
            "google227.jpg  google467.jpg  istockphoto154.jpg  istockphoto505.jpg\n",
            "google228.jpg  google468.jpg  istockphoto155.jpg  istockphoto50.jpg\n",
            "google229.jpg  google469.jpg  istockphoto156.jpg  istockphoto511.jpg\n",
            "google22.jpg   google46.jpg   istockphoto157.jpg  istockphoto512.jpg\n",
            "google230.jpg  google470.jpg  istockphoto16.jpg   istockphoto514.jpg\n",
            "google231.jpg  google471.jpg  istockphoto180.jpg  istockphoto516.jpg\n",
            "google232.jpg  google472.jpg  istockphoto181.jpg  istockphoto518.jpg\n",
            "google233.jpg  google473.jpg  istockphoto182.jpg  istockphoto51.jpg\n",
            "google234.jpg  google474.jpg  istockphoto183.jpg  istockphoto520.jpg\n",
            "google235.jpg  google475.jpg  istockphoto184.jpg  istockphoto521.jpg\n",
            "google236.jpg  google476.jpg  istockphoto185.jpg  istockphoto522.jpg\n",
            "google237.jpg  google477.jpg  istockphoto186.jpg  istockphoto523.jpg\n",
            "google238.jpg  google478.jpg  istockphoto187.jpg  istockphoto524.jpg\n",
            "google239.jpg  google479.jpg  istockphoto188.jpg  istockphoto525.jpg\n",
            "google23.jpg   google47.jpg   istockphoto189.jpg  istockphoto526.jpg\n",
            "google240.jpg  google480.jpg  istockphoto18.jpg   istockphoto528.jpg\n",
            "google241.jpg  google481.jpg  istockphoto190.jpg  istockphoto529.jpg\n",
            "google242.jpg  google482.jpg  istockphoto191.jpg  istockphoto52.jpg\n",
            "google243.jpg  google484.jpg  istockphoto192.jpg  istockphoto530.jpg\n",
            "google245.jpg  google485.jpg  istockphoto193.jpg  istockphoto531.jpg\n",
            "google246.jpg  google486.jpg  istockphoto194.jpg  istockphoto532.jpg\n",
            "google247.jpg  google487.jpg  istockphoto195.jpg  istockphoto533.jpg\n",
            "google248.jpg  google488.jpg  istockphoto196.jpg  istockphoto534.jpg\n",
            "google249.jpg  google489.jpg  istockphoto197.jpg  istockphoto535.jpg\n",
            "google24.jpg   google490.jpg  istockphoto198.jpg  istockphoto536.jpg\n",
            "google250.jpg  google492.jpg  istockphoto199.jpg  istockphoto537.jpg\n",
            "google251.jpg  google493.jpg  istockphoto19.jpg   istockphoto538.jpg\n",
            "google252.jpg  google494.jpg  istockphoto200.jpg  istockphoto53.jpg\n",
            "google253.jpg  google495.jpg  istockphoto202.jpg  istockphoto540.jpg\n",
            "google254.jpg  google497.jpg  istockphoto203.jpg  istockphoto541.jpg\n",
            "google255.jpg  google498.jpg  istockphoto204.jpg  istockphoto544.jpg\n",
            "google257.jpg  google499.jpg  istockphoto205.jpg  istockphoto545.jpg\n",
            "google258.jpg  google49.jpg   istockphoto206.jpg  istockphoto546.jpg\n",
            "google259.jpg  google4.jpg    istockphoto207.jpg  istockphoto547.jpg\n",
            "google25.jpg   google500.jpg  istockphoto208.jpg  istockphoto549.jpg\n",
            "google260.jpg  google502.jpg  istockphoto209.jpg  istockphoto54.jpg\n",
            "google262.jpg  google503.jpg  istockphoto20.jpg   istockphoto550.jpg\n",
            "google263.jpg  google504.jpg  istockphoto210.jpg  istockphoto552.jpg\n",
            "google264.jpg  google505.jpg  istockphoto211.jpg  istockphoto553.jpg\n",
            "google265.jpg  google506.jpg  istockphoto213.jpg  istockphoto554.jpg\n",
            "google266.jpg  google507.jpg  istockphoto214.jpg  istockphoto555.jpg\n",
            "google268.jpg  google508.jpg  istockphoto215.jpg  istockphoto556.jpg\n",
            "google269.jpg  google509.jpg  istockphoto216.jpg  istockphoto558.jpg\n",
            "google26.jpg   google50.jpg   istockphoto217.jpg  istockphoto559.jpg\n",
            "google271.jpg  google510.jpg  istockphoto218.jpg  istockphoto55.jpg\n",
            "google272.jpg  google511.jpg  istockphoto219.jpg  istockphoto560.jpg\n",
            "google273.jpg  google512.jpg  istockphoto21.jpg   istockphoto561.jpg\n",
            "google275.jpg  google514.jpg  istockphoto220.jpg  istockphoto562.jpg\n",
            "google276.jpg  google515.jpg  istockphoto221.jpg  istockphoto56.jpg\n",
            "google277.jpg  google517.jpg  istockphoto222.jpg  istockphoto583.jpg\n",
            "google278.jpg  google518.jpg  istockphoto223.jpg  istockphoto585.jpg\n",
            "google279.jpg  google519.jpg  istockphoto224.jpg  istockphoto586.jpg\n",
            "google27.jpg   google51.jpg   istockphoto225.jpg  istockphoto588.jpg\n",
            "google281.jpg  google520.jpg  istockphoto226.jpg  istockphoto590.jpg\n",
            "google282.jpg  google521.jpg  istockphoto227.jpg  istockphoto591.jpg\n",
            "google285.jpg  google522.jpg  istockphoto228.jpg  istockphoto592.jpg\n",
            "google287.jpg  google523.jpg  istockphoto229.jpg  istockphoto593.jpg\n",
            "google288.jpg  google524.jpg  istockphoto22.jpg   istockphoto594.jpg\n",
            "google289.jpg  google526.jpg  istockphoto230.jpg  istockphoto596.jpg\n",
            "google291.jpg  google527.jpg  istockphoto231.jpg  istockphoto597.jpg\n",
            "google292.jpg  google528.jpg  istockphoto232.jpg  istockphoto598.jpg\n",
            "google294.jpg  google529.jpg  istockphoto233.jpg  istockphoto59.jpg\n",
            "google295.jpg  google52.jpg   istockphoto234.jpg  istockphoto600.jpg\n",
            "google296.jpg  google530.jpg  istockphoto235.jpg  istockphoto602.jpg\n",
            "google297.jpg  google531.jpg  istockphoto238.jpg  istockphoto605.jpg\n",
            "google298.jpg  google532.jpg  istockphoto23.jpg   istockphoto606.jpg\n",
            "google299.jpg  google533.jpg  istockphoto24.jpg   istockphoto607.jpg\n",
            "google29.jpg   google534.jpg  istockphoto25.jpg   istockphoto609.jpg\n",
            "google2.jpg    google535.jpg  istockphoto260.jpg  istockphoto610.jpg\n",
            "google300.jpg  google536.jpg  istockphoto261.jpg  istockphoto611.jpg\n",
            "google301.jpg  google537.jpg  istockphoto262.jpg  istockphoto612.jpg\n",
            "google302.jpg  google538.jpg  istockphoto263.jpg  istockphoto613.jpg\n",
            "google303.jpg  google539.jpg  istockphoto264.jpg  istockphoto614.jpg\n",
            "google306.jpg  google53.jpg   istockphoto265.jpg  istockphoto615.jpg\n",
            "google307.jpg  google540.jpg  istockphoto267.jpg  istockphoto616.jpg\n",
            "google308.jpg  google541.jpg  istockphoto268.jpg  istockphoto617.jpg\n",
            "google309.jpg  google542.jpg  istockphoto269.jpg  istockphoto618.jpg\n",
            "google30.jpg   google543.jpg  istockphoto270.jpg  istockphoto61.jpg\n",
            "google310.jpg  google544.jpg  istockphoto271.jpg  istockphoto623.jpg\n",
            "google311.jpg  google545.jpg  istockphoto272.jpg  istockphoto627.jpg\n",
            "google312.jpg  google547.jpg  istockphoto273.jpg  istockphoto628.jpg\n",
            "google313.jpg  google548.jpg  istockphoto274.jpg  istockphoto62.jpg\n",
            "google314.jpg  google54.jpg   istockphoto275.jpg  istockphoto631.jpg\n",
            "google315.jpg  google550.jpg  istockphoto277.jpg  istockphoto632.jpg\n",
            "google318.jpg  google551.jpg  istockphoto278.jpg  istockphoto633.jpg\n",
            "google319.jpg  google552.jpg  istockphoto27.jpg   istockphoto634.jpg\n",
            "google31.jpg   google553.jpg  istockphoto281.jpg  istockphoto635.jpg\n",
            "google320.jpg  google554.jpg  istockphoto283.jpg  istockphoto637.jpg\n",
            "google321.jpg  google556.jpg  istockphoto284.jpg  istockphoto639.jpg\n",
            "google322.jpg  google557.jpg  istockphoto287.jpg  istockphoto63.jpg\n",
            "google323.jpg  google558.jpg  istockphoto289.jpg  istockphoto640.jpg\n",
            "google325.jpg  google559.jpg  istockphoto28.jpg   istockphoto642.jpg\n",
            "google326.jpg  google55.jpg   istockphoto290.jpg  istockphoto64.jpg\n",
            "google329.jpg  google560.jpg  istockphoto291.jpg  istockphoto65.jpg\n",
            "google32.jpg   google562.jpg  istockphoto292.jpg  istockphoto66.jpg\n",
            "google330.jpg  google563.jpg  istockphoto294.jpg  istockphoto67.jpg\n",
            "google331.jpg  google564.jpg  istockphoto295.jpg  istockphoto68.jpg\n",
            "google333.jpg  google565.jpg  istockphoto296.jpg  istockphoto69.jpg\n",
            "google334.jpg  google566.jpg  istockphoto297.jpg  istockphoto70.jpg\n",
            "google335.jpg  google567.jpg  istockphoto298.jpg  istockphoto72.jpg\n",
            "google336.jpg  google568.jpg  istockphoto299.jpg  istockphoto75.jpg\n",
            "google337.jpg  google569.jpg  istockphoto303.jpg  istockphoto76.jpg\n",
            "google338.jpg  google56.jpg   istockphoto304.jpg  istockphoto97.jpg\n",
            "google339.jpg  google570.jpg  istockphoto306.jpg  istockphoto99.jpg\n",
            "google33.jpg   google571.jpg  istockphoto307.jpg\n"
          ]
        }
      ],
      "source": [
        "!ls dataset/archive/Butterfly/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "33ba3c5e-3170-406f-b5b5-05bd5a7582e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ba3c5e-3170-406f-b5b5-05bd5a7582e8",
        "outputId": "10dfb2d8-442b-40f4-931d-0903fac1eaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Predicted class: Dragonfly\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "img_path = \"dataset/archive/Butterfly/google0.jpg\"  # Updated to a valid filename\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = train_generator.class_indices\n",
        "predicted_class = list(predicted_class.keys())[np.argmax(prediction)]\n",
        "\n",
        "print(\"Predicted class:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "84b38f6f-9c87-4860-88c2-c377ec827082",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84b38f6f-9c87-4860-88c2-c377ec827082",
        "outputId": "ee19f582-5b93-48f7-973c-5f219cda43ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"insect_classifier_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
